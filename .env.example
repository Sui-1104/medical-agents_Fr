# Core Identity
AGENT_NAME=medical_agents

# Model Configuration
# Use provider/model-name for OpenRouter (e.g., openrouter/google/gemini-2.0-flash-001)
ROOT_AGENT_MODEL=google/gemini-2.0-flash-001

# API Keys
OPENROUTER_API_KEY=your-openrouter-key-here
GITHUB_TOKEN=your-github-token-here


LOCAL_LLM_API_BASE=http://localhost:1234/v1
LOCAL_LLM_MODEL=openai/medgemma



# Database Configuration
# asyncpg requires ssl=require instead of sslmode=require
DATABASE_URL=postgresql://user:pass@host:port/dbname?ssl=require
DB_POOL_PRE_PING=true
DB_POOL_RECYCLE=1800
DB_POOL_SIZE=5
DB_MAX_OVERFLOW=10
DB_POOL_TIMEOUT=30

# Server Configuration
LOG_LEVEL=INFO
HOST=0.0.0.0
PORT=8080

# Feature Flags
SERVE_WEB_INTERFACE=true
RELOAD_AGENTS=true
OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT=false

# ---------------------------------------------------------------------------
# Observability Configuration (Choose One)
# ---------------------------------------------------------------------------

# Option 1: Langfuse (Recommended)
# Setting these automatically configures OTEL_EXPORTER_OTLP_* for Langfuse.
# LANGFUSE_PUBLIC_KEY=pk-lf-...
# LANGFUSE_SECRET_KEY=sk-lf-...
# LANGFUSE_BASE_URL=https://cloud.langfuse.com

# Option 2: Generic OpenTelemetry (Jaeger, Honeycomb, etc.)
# Use this if you are NOT using Langfuse.
# OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318/v1/traces
# OTEL_EXPORTER_OTLP_PROTOCOL=http/protobuf
# OTEL_EXPORTER_OTLP_HEADERS=Authorization=Basic ...
